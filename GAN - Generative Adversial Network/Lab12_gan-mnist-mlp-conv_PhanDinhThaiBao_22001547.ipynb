{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.14.0"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"8b6cc5a0","cell_type":"markdown","source":"# MLP-GAN và Conv-GAN trên MNIST\n\nNotebook này chứa hai biến thể:\n- **MLP-GAN** trên ảnh MNIST 28×28\n- **Conv-GAN** trên ảnh MNIST resize 64×64\n\nBạn có thể chỉnh tham số trực tiếp trong cell cấu hình bên dưới.","metadata":{}},{"id":"edd86157","cell_type":"code","source":"# Cài đặt (chỉ cần chạy nếu thiếu thư viện)\n# !pip install torch torchvision matplotlib\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:38:37.169044Z","iopub.execute_input":"2025-12-08T15:38:37.169739Z","iopub.status.idle":"2025-12-08T15:38:37.173464Z","shell.execute_reply.started":"2025-12-08T15:38:37.169715Z","shell.execute_reply":"2025-12-08T15:38:37.172809Z"}},"outputs":[],"execution_count":1},{"id":"594d2647","cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom torchvision.utils import make_grid, save_image\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:38:37.174531Z","iopub.execute_input":"2025-12-08T15:38:37.174765Z","iopub.status.idle":"2025-12-08T15:38:43.250949Z","shell.execute_reply.started":"2025-12-08T15:38:37.174749Z","shell.execute_reply":"2025-12-08T15:38:43.250227Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":2},{"id":"e4464295","cell_type":"code","source":"# Cấu hình tham số (chỉnh trực tiếp ở đây)\nBASE_DIR = \"/kaggle/working/\"\nARCH = \"mlp\"  # 'mlp' or 'conv'\nEPOCHS = 20\nBATCH_SIZE = 128\nLATENT_DIM = 100\nLR = 2e-4\nOUTPUT_DIR = os.path.join(BASE_DIR, \"outputs_mnist\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T16:03:17.545973Z","iopub.execute_input":"2025-12-08T16:03:17.546629Z","iopub.status.idle":"2025-12-08T16:03:17.551284Z","shell.execute_reply.started":"2025-12-08T16:03:17.546597Z","shell.execute_reply":"2025-12-08T16:03:17.550523Z"}},"outputs":[],"execution_count":10},{"id":"c096af58","cell_type":"code","source":"# Định nghĩa MLP-GAN\n\nclass MLPGenerator(nn.Module):\n    def __init__(self, latent_dim=100, img_size=28 * 28):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(latent_dim, 256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(256, 512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(512, 1024),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(1024, img_size),\n            nn.Tanh()\n        )\n        self.img_size = img_size\n\n    def forward(self, z):\n        x = self.model(z)\n        return x.view(x.size(0), 1, 28, 28)\n\n\nclass MLPDiscriminator(nn.Module):\n    def __init__(self, img_size=28 * 28):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(img_size, 512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(512, 256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(256, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        return self.model(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:38:43.257197Z","iopub.execute_input":"2025-12-08T15:38:43.257476Z","iopub.status.idle":"2025-12-08T15:38:43.274589Z","shell.execute_reply.started":"2025-12-08T15:38:43.257433Z","shell.execute_reply":"2025-12-08T15:38:43.273886Z"}},"outputs":[],"execution_count":4},{"id":"6a460352","cell_type":"code","source":"# Định nghĩa Conv-GAN (kiểu DCGAN nhỏ cho MNIST 64x64)\n\nclass ConvGenerator(nn.Module):\n    def __init__(self, nz=100, ngf=64, nc=1):\n        super().__init__()\n        self.main = nn.Sequential(\n            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 8),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh()\n        )\n\n    def forward(self, z):\n        return self.main(z)\n\n\nclass ConvDiscriminator(nn.Module):\n    def __init__(self, nc=1, ndf=64):\n        super().__init__()\n        self.main = nn.Sequential(\n            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 8),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        out = self.main(x)\n        return out.view(-1, 1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:38:43.276101Z","iopub.execute_input":"2025-12-08T15:38:43.276612Z","iopub.status.idle":"2025-12-08T15:38:43.288913Z","shell.execute_reply.started":"2025-12-08T15:38:43.276513Z","shell.execute_reply":"2025-12-08T15:38:43.288326Z"}},"outputs":[],"execution_count":5},{"id":"702fccc6","cell_type":"code","source":"# Hàm sinh noise\n\ndef sample_noise_mlp(batch_size, latent_dim, device):\n    return torch.randn(batch_size, latent_dim, device=device)\n\n\ndef sample_noise_conv(batch_size, nz, device):\n    return torch.randn(batch_size, nz, 1, 1, device=device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:38:43.289478Z","iopub.execute_input":"2025-12-08T15:38:43.289725Z","iopub.status.idle":"2025-12-08T15:38:43.304187Z","shell.execute_reply.started":"2025-12-08T15:38:43.289702Z","shell.execute_reply":"2025-12-08T15:38:43.303575Z"}},"outputs":[],"execution_count":6},{"id":"dd1868af","cell_type":"code","source":"# Vòng lặp huấn luyện chung cho cả MLP và Conv\n\ndef train_gan_mnist(arch=\"mlp\", epochs=20, batch_size=128, latent_dim=100, lr=2e-4, outdir=\"outputs_mnist\"):\n    os.makedirs(outdir, exist_ok=True)\n\n    if arch == \"mlp\":\n        img_size = 28\n        transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize((0.5,), (0.5,))\n        ])\n    else:\n        img_size = 64\n        transform = transforms.Compose([\n            transforms.Resize(img_size),\n            transforms.ToTensor(),\n            transforms.Normalize((0.5,), (0.5,))\n        ])\n\n    dataset = datasets.MNIST(root=\"data\", train=True, transform=transform, download=True)\n    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    if arch == \"mlp\":\n        G = MLPGenerator(latent_dim, img_size * img_size).to(device)\n        D = MLPDiscriminator(img_size * img_size).to(device)\n    else:\n        G = ConvGenerator(nz=latent_dim, ngf=64, nc=1).to(device)\n        D = ConvDiscriminator(nc=1, ndf=64).to(device)\n\n    criterion = nn.BCELoss()\n    optimizer_G = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n    optimizer_D = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n\n    for epoch in range(epochs):\n        for i, (real_imgs, _) in enumerate(loader):\n            real_imgs = real_imgs.to(device)\n            cur_bs = real_imgs.size(0)\n\n            # Train D\n            optimizer_D.zero_grad()\n            labels_real = torch.ones(cur_bs, 1, device=device)\n            labels_fake = torch.zeros(cur_bs, 1, device=device)\n\n            out_real = D(real_imgs)\n            loss_D_real = criterion(out_real, labels_real)\n\n            if arch == \"mlp\":\n                z = sample_noise_mlp(cur_bs, latent_dim, device)\n            else:\n                z = sample_noise_conv(cur_bs, latent_dim, device)\n\n            fake_imgs = G(z).detach()\n            out_fake = D(fake_imgs)\n            loss_D_fake = criterion(out_fake, labels_fake)\n\n            loss_D = loss_D_real + loss_D_fake\n            loss_D.backward()\n            optimizer_D.step()\n\n            # Train G\n            optimizer_G.zero_grad()\n            if arch == \"mlp\":\n                z = sample_noise_mlp(cur_bs, latent_dim, device)\n            else:\n                z = sample_noise_conv(cur_bs, latent_dim, device)\n\n            fake_imgs = G(z)\n            out_fake_for_G = D(fake_imgs)\n            loss_G = criterion(out_fake_for_G, labels_real)\n            loss_G.backward()\n            optimizer_G.step()\n\n            if i % 200 == 0:\n                print(f\"[{arch}] Epoch [{epoch+1}/{epochs}] \"\n                      f\"Step [{i}/{len(loader)}] \"\n                      f\"Loss_D: {loss_D.item():.4f}, Loss_G: {loss_G.item():.4f}\")\n\n        # Lưu ảnh mỗi epoch\n        with torch.no_grad():\n            if arch == \"mlp\":\n                z = sample_noise_mlp(64, latent_dim, device)\n            else:\n                z = sample_noise_conv(64, latent_dim, device)\n            fake = G(z).cpu()\n            fake = (fake + 1) / 2\n            grid = make_grid(fake, nrow=8)\n            save_image(grid, os.path.join(outdir, f\"{arch}_fake_epoch_{epoch+1:03d}.png\"))\n\n    print(\"Hoàn thành huấn luyện, ảnh sinh ra lưu trong:\", outdir)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:38:43.304848Z","iopub.execute_input":"2025-12-08T15:38:43.305043Z","iopub.status.idle":"2025-12-08T15:38:43.318243Z","shell.execute_reply.started":"2025-12-08T15:38:43.305019Z","shell.execute_reply":"2025-12-08T15:38:43.317657Z"}},"outputs":[],"execution_count":7},{"id":"f8316c0e","cell_type":"code","source":"# CHẠY THỰC NGHIỆM\n# Chỉ cần chạy cell này sau khi chỉnh tham số ở cell cấu hình.\n\ntrain_gan_mnist(\n    arch=ARCH,\n    epochs=EPOCHS,\n    batch_size=BATCH_SIZE,\n    latent_dim=LATENT_DIM,\n    lr=LR,\n    outdir=OUTPUT_DIR\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:38:43.319081Z","iopub.execute_input":"2025-12-08T15:38:43.319355Z","iopub.status.idle":"2025-12-08T15:51:54.090054Z","shell.execute_reply.started":"2025-12-08T15:38:43.319332Z","shell.execute_reply":"2025-12-08T15:51:54.089302Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 9.91M/9.91M [00:00<00:00, 17.9MB/s]\n100%|██████████| 28.9k/28.9k [00:00<00:00, 479kB/s]\n100%|██████████| 1.65M/1.65M [00:00<00:00, 4.47MB/s]\n100%|██████████| 4.54k/4.54k [00:00<00:00, 8.37MB/s]\n","output_type":"stream"},{"name":"stdout","text":"[conv] Epoch [1/20] Step [0/469] Loss_D: 1.5851, Loss_G: 1.8070\n[conv] Epoch [1/20] Step [200/469] Loss_D: 0.5102, Loss_G: 4.7396\n[conv] Epoch [1/20] Step [400/469] Loss_D: 1.0117, Loss_G: 3.8880\n[conv] Epoch [2/20] Step [0/469] Loss_D: 0.8209, Loss_G: 0.7068\n[conv] Epoch [2/20] Step [200/469] Loss_D: 0.8529, Loss_G: 2.2823\n[conv] Epoch [2/20] Step [400/469] Loss_D: 0.3622, Loss_G: 1.8367\n[conv] Epoch [3/20] Step [0/469] Loss_D: 0.7558, Loss_G: 2.1386\n[conv] Epoch [3/20] Step [200/469] Loss_D: 0.6497, Loss_G: 1.3512\n[conv] Epoch [3/20] Step [400/469] Loss_D: 1.1309, Loss_G: 1.2816\n[conv] Epoch [4/20] Step [0/469] Loss_D: 1.3422, Loss_G: 7.9889\n[conv] Epoch [4/20] Step [200/469] Loss_D: 0.2854, Loss_G: 3.6206\n[conv] Epoch [4/20] Step [400/469] Loss_D: 0.4566, Loss_G: 4.2112\n[conv] Epoch [5/20] Step [0/469] Loss_D: 0.0675, Loss_G: 4.3343\n[conv] Epoch [5/20] Step [200/469] Loss_D: 0.0495, Loss_G: 5.1526\n[conv] Epoch [5/20] Step [400/469] Loss_D: 0.3908, Loss_G: 3.0748\n[conv] Epoch [6/20] Step [0/469] Loss_D: 0.2493, Loss_G: 3.9742\n[conv] Epoch [6/20] Step [200/469] Loss_D: 0.0804, Loss_G: 4.8216\n[conv] Epoch [6/20] Step [400/469] Loss_D: 0.0328, Loss_G: 4.5434\n[conv] Epoch [7/20] Step [0/469] Loss_D: 0.1551, Loss_G: 3.9812\n[conv] Epoch [7/20] Step [200/469] Loss_D: 0.2066, Loss_G: 1.9332\n[conv] Epoch [7/20] Step [400/469] Loss_D: 0.0304, Loss_G: 4.7578\n[conv] Epoch [8/20] Step [0/469] Loss_D: 0.1689, Loss_G: 5.4183\n[conv] Epoch [8/20] Step [200/469] Loss_D: 0.0225, Loss_G: 5.8666\n[conv] Epoch [8/20] Step [400/469] Loss_D: 0.1921, Loss_G: 3.3077\n[conv] Epoch [9/20] Step [0/469] Loss_D: 0.2007, Loss_G: 4.1486\n[conv] Epoch [9/20] Step [200/469] Loss_D: 0.5131, Loss_G: 2.6367\n[conv] Epoch [9/20] Step [400/469] Loss_D: 3.0953, Loss_G: 5.0228\n[conv] Epoch [10/20] Step [0/469] Loss_D: 0.0465, Loss_G: 4.0319\n[conv] Epoch [10/20] Step [200/469] Loss_D: 0.0426, Loss_G: 7.2952\n[conv] Epoch [10/20] Step [400/469] Loss_D: 0.1234, Loss_G: 1.8867\n[conv] Epoch [11/20] Step [0/469] Loss_D: 0.7132, Loss_G: 2.2388\n[conv] Epoch [11/20] Step [200/469] Loss_D: 0.0357, Loss_G: 5.9923\n[conv] Epoch [11/20] Step [400/469] Loss_D: 0.5669, Loss_G: 2.4734\n[conv] Epoch [12/20] Step [0/469] Loss_D: 0.1823, Loss_G: 4.5710\n[conv] Epoch [12/20] Step [200/469] Loss_D: 0.0603, Loss_G: 4.0631\n[conv] Epoch [12/20] Step [400/469] Loss_D: 0.0155, Loss_G: 5.3516\n[conv] Epoch [13/20] Step [0/469] Loss_D: 0.0103, Loss_G: 6.3089\n[conv] Epoch [13/20] Step [200/469] Loss_D: 0.0093, Loss_G: 6.8004\n[conv] Epoch [13/20] Step [400/469] Loss_D: 0.3233, Loss_G: 2.1323\n[conv] Epoch [14/20] Step [0/469] Loss_D: 3.8182, Loss_G: 1.3378\n[conv] Epoch [14/20] Step [200/469] Loss_D: 0.1729, Loss_G: 3.0562\n[conv] Epoch [14/20] Step [400/469] Loss_D: 0.0203, Loss_G: 5.3274\n[conv] Epoch [15/20] Step [0/469] Loss_D: 0.0171, Loss_G: 5.8306\n[conv] Epoch [15/20] Step [200/469] Loss_D: 0.0193, Loss_G: 6.0452\n[conv] Epoch [15/20] Step [400/469] Loss_D: 0.2255, Loss_G: 3.2387\n[conv] Epoch [16/20] Step [0/469] Loss_D: 0.1902, Loss_G: 4.5091\n[conv] Epoch [16/20] Step [200/469] Loss_D: 0.0340, Loss_G: 4.7001\n[conv] Epoch [16/20] Step [400/469] Loss_D: 0.4763, Loss_G: 2.6997\n[conv] Epoch [17/20] Step [0/469] Loss_D: 0.1796, Loss_G: 2.6717\n[conv] Epoch [17/20] Step [200/469] Loss_D: 0.3588, Loss_G: 2.7657\n[conv] Epoch [17/20] Step [400/469] Loss_D: 0.0309, Loss_G: 4.7831\n[conv] Epoch [18/20] Step [0/469] Loss_D: 0.0134, Loss_G: 5.4703\n[conv] Epoch [18/20] Step [200/469] Loss_D: 0.0245, Loss_G: 5.0849\n[conv] Epoch [18/20] Step [400/469] Loss_D: 0.0100, Loss_G: 6.2248\n[conv] Epoch [19/20] Step [0/469] Loss_D: 0.0073, Loss_G: 6.3871\n[conv] Epoch [19/20] Step [200/469] Loss_D: 0.6371, Loss_G: 2.2558\n[conv] Epoch [19/20] Step [400/469] Loss_D: 1.1249, Loss_G: 1.3606\n[conv] Epoch [20/20] Step [0/469] Loss_D: 0.1045, Loss_G: 2.6776\n[conv] Epoch [20/20] Step [200/469] Loss_D: 0.9102, Loss_G: 2.4888\n[conv] Epoch [20/20] Step [400/469] Loss_D: 0.0130, Loss_G: 5.7118\nHoàn thành huấn luyện, ảnh sinh ra lưu trong: /kaggle/working/outputs_mnist\n","output_type":"stream"}],"execution_count":8},{"id":"b3da91fc-ee66-4574-b34e-67e97cadd2a8","cell_type":"code","source":"train_gan_mnist(\n    arch=ARCH,\n    epochs=EPOCHS,\n    batch_size=BATCH_SIZE,\n    latent_dim=LATENT_DIM,\n    lr=LR,\n    outdir=OUTPUT_DIR\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T16:03:22.154409Z","iopub.execute_input":"2025-12-08T16:03:22.155107Z","iopub.status.idle":"2025-12-08T16:07:33.934835Z","shell.execute_reply.started":"2025-12-08T16:03:22.155084Z","shell.execute_reply":"2025-12-08T16:07:33.934128Z"}},"outputs":[{"name":"stdout","text":"[mlp] Epoch [1/20] Step [0/469] Loss_D: 1.4150, Loss_G: 0.6960\n[mlp] Epoch [1/20] Step [200/469] Loss_D: 1.2797, Loss_G: 0.8584\n[mlp] Epoch [1/20] Step [400/469] Loss_D: 1.4556, Loss_G: 0.9871\n[mlp] Epoch [2/20] Step [0/469] Loss_D: 0.9636, Loss_G: 1.3793\n[mlp] Epoch [2/20] Step [200/469] Loss_D: 0.8600, Loss_G: 1.5466\n[mlp] Epoch [2/20] Step [400/469] Loss_D: 1.1156, Loss_G: 1.2645\n[mlp] Epoch [3/20] Step [0/469] Loss_D: 0.9919, Loss_G: 1.3817\n[mlp] Epoch [3/20] Step [200/469] Loss_D: 1.1555, Loss_G: 2.6992\n[mlp] Epoch [3/20] Step [400/469] Loss_D: 0.8441, Loss_G: 1.5528\n[mlp] Epoch [4/20] Step [0/469] Loss_D: 0.9335, Loss_G: 0.9194\n[mlp] Epoch [4/20] Step [200/469] Loss_D: 1.0834, Loss_G: 1.9505\n[mlp] Epoch [4/20] Step [400/469] Loss_D: 0.8373, Loss_G: 2.7357\n[mlp] Epoch [5/20] Step [0/469] Loss_D: 0.7174, Loss_G: 1.3401\n[mlp] Epoch [5/20] Step [200/469] Loss_D: 0.9970, Loss_G: 1.5264\n[mlp] Epoch [5/20] Step [400/469] Loss_D: 0.8729, Loss_G: 1.1432\n[mlp] Epoch [6/20] Step [0/469] Loss_D: 0.8901, Loss_G: 2.6562\n[mlp] Epoch [6/20] Step [200/469] Loss_D: 0.9191, Loss_G: 1.2056\n[mlp] Epoch [6/20] Step [400/469] Loss_D: 0.7024, Loss_G: 1.9218\n[mlp] Epoch [7/20] Step [0/469] Loss_D: 0.8016, Loss_G: 2.5775\n[mlp] Epoch [7/20] Step [200/469] Loss_D: 1.5041, Loss_G: 0.8375\n[mlp] Epoch [7/20] Step [400/469] Loss_D: 0.7343, Loss_G: 1.3845\n[mlp] Epoch [8/20] Step [0/469] Loss_D: 0.7402, Loss_G: 2.0861\n[mlp] Epoch [8/20] Step [200/469] Loss_D: 1.0123, Loss_G: 3.0036\n[mlp] Epoch [8/20] Step [400/469] Loss_D: 0.5988, Loss_G: 2.3271\n[mlp] Epoch [9/20] Step [0/469] Loss_D: 1.2004, Loss_G: 1.1365\n[mlp] Epoch [9/20] Step [200/469] Loss_D: 0.6814, Loss_G: 2.3290\n[mlp] Epoch [9/20] Step [400/469] Loss_D: 0.8598, Loss_G: 2.0060\n[mlp] Epoch [10/20] Step [0/469] Loss_D: 0.6260, Loss_G: 1.7788\n[mlp] Epoch [10/20] Step [200/469] Loss_D: 0.7576, Loss_G: 1.2029\n[mlp] Epoch [10/20] Step [400/469] Loss_D: 0.6499, Loss_G: 2.1955\n[mlp] Epoch [11/20] Step [0/469] Loss_D: 0.6316, Loss_G: 1.8599\n[mlp] Epoch [11/20] Step [200/469] Loss_D: 0.6071, Loss_G: 1.5480\n[mlp] Epoch [11/20] Step [400/469] Loss_D: 0.6533, Loss_G: 1.8394\n[mlp] Epoch [12/20] Step [0/469] Loss_D: 0.7561, Loss_G: 2.7394\n[mlp] Epoch [12/20] Step [200/469] Loss_D: 0.7259, Loss_G: 1.5964\n[mlp] Epoch [12/20] Step [400/469] Loss_D: 0.7763, Loss_G: 2.2189\n[mlp] Epoch [13/20] Step [0/469] Loss_D: 0.8545, Loss_G: 1.9293\n[mlp] Epoch [13/20] Step [200/469] Loss_D: 1.0221, Loss_G: 0.8827\n[mlp] Epoch [13/20] Step [400/469] Loss_D: 1.1100, Loss_G: 1.7964\n[mlp] Epoch [14/20] Step [0/469] Loss_D: 1.0668, Loss_G: 1.3029\n[mlp] Epoch [14/20] Step [200/469] Loss_D: 0.9391, Loss_G: 0.8837\n[mlp] Epoch [14/20] Step [400/469] Loss_D: 1.0258, Loss_G: 1.2908\n[mlp] Epoch [15/20] Step [0/469] Loss_D: 1.0504, Loss_G: 1.7745\n[mlp] Epoch [15/20] Step [200/469] Loss_D: 1.0820, Loss_G: 1.2940\n[mlp] Epoch [15/20] Step [400/469] Loss_D: 1.0430, Loss_G: 0.9098\n[mlp] Epoch [16/20] Step [0/469] Loss_D: 1.0983, Loss_G: 0.8263\n[mlp] Epoch [16/20] Step [200/469] Loss_D: 0.9042, Loss_G: 1.1349\n[mlp] Epoch [16/20] Step [400/469] Loss_D: 1.0530, Loss_G: 1.4069\n[mlp] Epoch [17/20] Step [0/469] Loss_D: 1.1375, Loss_G: 0.9367\n[mlp] Epoch [17/20] Step [200/469] Loss_D: 1.0715, Loss_G: 1.0212\n[mlp] Epoch [17/20] Step [400/469] Loss_D: 1.1341, Loss_G: 0.7673\n[mlp] Epoch [18/20] Step [0/469] Loss_D: 1.0787, Loss_G: 1.1973\n[mlp] Epoch [18/20] Step [200/469] Loss_D: 1.1777, Loss_G: 1.3309\n[mlp] Epoch [18/20] Step [400/469] Loss_D: 1.1392, Loss_G: 1.4932\n[mlp] Epoch [19/20] Step [0/469] Loss_D: 1.1016, Loss_G: 0.9096\n[mlp] Epoch [19/20] Step [200/469] Loss_D: 1.1457, Loss_G: 1.3289\n[mlp] Epoch [19/20] Step [400/469] Loss_D: 1.1700, Loss_G: 1.3789\n[mlp] Epoch [20/20] Step [0/469] Loss_D: 1.0605, Loss_G: 1.3038\n[mlp] Epoch [20/20] Step [200/469] Loss_D: 1.2400, Loss_G: 0.8336\n[mlp] Epoch [20/20] Step [400/469] Loss_D: 1.1216, Loss_G: 1.1234\nHoàn thành huấn luyện, ảnh sinh ra lưu trong: /kaggle/working/outputs_mnist\n","output_type":"stream"}],"execution_count":11}]}
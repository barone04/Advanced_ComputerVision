{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a8ec4c23",
      "metadata": {
        "id": "a8ec4c23"
      },
      "source": [
        "# VRD Scene Graph with GAT-like (padded) + YOLOv8 Detection Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "599d9126",
      "metadata": {
        "id": "599d9126"
      },
      "source": [
        "Notebook này tương thích VRD gốc, huấn luyện GraphClassifier & RelationExtractor, và inference từ ảnh qua YOLOv8 (nếu có)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8f80da2",
      "metadata": {
        "id": "d8f80da2"
      },
      "source": [
        "## 0) Thiết lập & (tuỳ chọn) cài YOLOv8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d5e4086",
      "metadata": {
        "id": "9d5e4086",
        "outputId": "190532d0-8abe-4a50-b8fc-545b90c1691b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# !pip -q install ultralytics\n",
        "import os, json, numpy as np, math, warnings\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch import optim\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "SEED=123\n",
        "np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device)\n",
        "try:\n",
        "    from ultralytics import YOLO\n",
        "    HAS_YOLO=True\n",
        "except Exception:\n",
        "    HAS_YOLO=False\n",
        "    print('[INFO] YOLOv8 chưa sẵn sàng. Bạn có thể cài ultralytics để dùng detector.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01d38793",
      "metadata": {
        "id": "01d38793"
      },
      "source": [
        "## 1) Cấu hình đường dẫn VRD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7708a641",
      "metadata": {
        "id": "7708a641",
        "outputId": "ff64b6d2-49e2-4d99-fd7e-0a75c8c3fb0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VRD_TRAIN_JSON: H:\\Download\\vrd\\sg_train_annotations.json\n",
            "VRD_TEST_JSON : H:\\Download\\vrd\\sg_test_annotations.json\n",
            "VRD_TRAIN_DIR : H:\\Download\\vrd\\sg_train_images\n",
            "VRD_TEST_DIR  : H:\\Download\\vrd\\sg_test_images\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ROOT_PATH = \"H:/Download/vrd/\"\n",
        "\n",
        "VRD_ROOT = Path(ROOT_PATH)\n",
        "POSSIBLE_IMG_DIRS_TRAIN=[ROOT_PATH + 'sg_train_images','images/train','images/train_images','train']\n",
        "POSSIBLE_IMG_DIRS_TEST =[ROOT_PATH + 'sg_test_images','images/test','images/test_images','test']\n",
        "POSSIBLE_TRAIN_JSON=[ROOT_PATH + 'sg_train_annotations.json','annotations_train.json','vrd_train.json']\n",
        "POSSIBLE_TEST_JSON =[ROOT_PATH + 'sg_test_annotations.json','annotations_test.json','vrd_test.json']\n",
        "\n",
        "def find_first_exists(base: Path, candidates):\n",
        "    for c in candidates:\n",
        "        p = base / c\n",
        "        if p.exists(): return p\n",
        "    return None\n",
        "\n",
        "VRD_TRAIN_JSON = find_first_exists(VRD_ROOT, POSSIBLE_TRAIN_JSON)\n",
        "VRD_TEST_JSON  = find_first_exists(VRD_ROOT, POSSIBLE_TEST_JSON)\n",
        "VRD_TRAIN_DIR  = find_first_exists(VRD_ROOT, POSSIBLE_IMG_DIRS_TRAIN)\n",
        "VRD_TEST_DIR   = find_first_exists(VRD_ROOT, POSSIBLE_IMG_DIRS_TEST)\n",
        "\n",
        "print('VRD_TRAIN_JSON:', VRD_TRAIN_JSON)\n",
        "print('VRD_TEST_JSON :', VRD_TEST_JSON)\n",
        "print('VRD_TRAIN_DIR :', VRD_TRAIN_DIR)\n",
        "print('VRD_TEST_DIR  :', VRD_TEST_DIR)\n",
        "assert VRD_TRAIN_JSON is not None and VRD_TRAIN_DIR is not None, \"Thiếu train.json/dir\"\n",
        "assert VRD_TEST_JSON is not None and VRD_TEST_DIR is not None, \"Thiếu test.json/dir\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b97d329b",
      "metadata": {
        "id": "b97d329b"
      },
      "source": [
        "## 2) Đọc annotations VRD → vocab + đồ thị"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "895ecac6-df38-4a71-8516-19ee044b29d9",
      "metadata": {
        "id": "895ecac6-df38-4a71-8516-19ee044b29d9",
        "outputId": "467fe72e-8337-4f1e-ff97-e2963f8659e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train items: 4000 | Test items: 1000\n",
            "Ví dụ item[0] keys: ['relationships', 'photo_id', 'height', 'width', 'objects', 'filename']\n",
            "Số lượng categories: 6455\n",
            "Một vài category: ['1', '1003', '11', '13', '148', '15', '18', '2', '2 hands', '20', '2012', '2013', '2375', '3', '3pm', '4', '40', '50', '6', '6am']\n",
            "Số lượng predicates (không tính 'none'): 1310\n",
            "Một vài predicates: ['ab', 'aboe', 'aboev', 'about', 'about to catch', 'about to cut', 'about to hit', 'abouve', 'above', 'aboveq', 'abovw', 'across', 'across from', 'acrosss', 'acrosst', 'adjacent ot', 'adjacent to', 'adjusting', 'adjusts', 'admiring']\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# 1) Đọc JSON VRD thô\n",
        "def read_vrd_json(json_path: Path):\n",
        "    with open(json_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "# 2) Chuẩn hoá: raw -> list item (mỗi item ~ 1 ảnh)\n",
        "def normalize_items(raw):\n",
        "    if isinstance(raw, list):\n",
        "        return raw\n",
        "    if isinstance(raw, dict):\n",
        "        for key in ['images', 'annotations', 'data']:\n",
        "            if key in raw and isinstance(raw[key], list):\n",
        "                return raw[key]\n",
        "    return [raw]\n",
        "\n",
        "train_raw = read_vrd_json(VRD_TRAIN_JSON)\n",
        "test_raw  = read_vrd_json(VRD_TEST_JSON)\n",
        "\n",
        "train_ann = normalize_items(train_raw)\n",
        "test_ann  = normalize_items(test_raw)\n",
        "\n",
        "print(\"Train items:\", len(train_ann), \"| Test items:\", len(test_ann))\n",
        "print(\"Ví dụ item[0] keys:\", list(train_ann[0].keys()))\n",
        "# -> ['relationships', 'photo_id', 'height', 'width', 'objects', 'filename']\n",
        "\n",
        "# ================== PARSER CHUẨN CHO SCHEMA NÀY ==================\n",
        "\n",
        "def iter_relationships_vrd(item):\n",
        "    \"\"\"\n",
        "    Chuẩn hoá 1 item (1 ảnh) thành các quan hệ:\n",
        "      { 'subj': <tên lớp chủ thể>, 'obj': <tên lớp đối tượng>, 'predicate': <tên quan hệ> }\n",
        "\n",
        "    Dựa trên schema:\n",
        "      - item['relationships']: list các dict\n",
        "        mỗi dict có:\n",
        "          'text': ['woman', 'wears', 'shirt']\n",
        "          'objects': [0, 1]  # không dùng cũng được\n",
        "          'relationship': 'wearing'\n",
        "    \"\"\"\n",
        "    rels = item.get('relationships', [])\n",
        "\n",
        "    for r in rels:\n",
        "        text = r.get('text', [])\n",
        "        # text = [subj, verb, obj] theo ví dụ bạn gửi\n",
        "        subj_name = text[0] if len(text) > 0 else 'unknown'\n",
        "        obj_name  = text[2] if len(text) > 2 else 'unknown'\n",
        "\n",
        "        # quan hệ chính: ưu tiên field 'relationship'\n",
        "        rel_name = r.get('relationship')\n",
        "        if rel_name is None:\n",
        "            # fallback: lấy từ text[1] nếu có\n",
        "            rel_name = text[1] if len(text) > 1 else 'none'\n",
        "\n",
        "        # chuẩn hoá sang string\n",
        "        subj_name = str(subj_name) if subj_name is not None else 'unknown'\n",
        "        obj_name  = str(obj_name)  if obj_name  is not None else 'unknown'\n",
        "        rel_name  = str(rel_name)  if rel_name  is not None else 'none'\n",
        "\n",
        "        yield {\n",
        "            'subj': subj_name,\n",
        "            'obj':  obj_name,\n",
        "            'predicate': rel_name\n",
        "        }\n",
        "\n",
        "# ============ XÂY VOCAB TỪ TRAIN + TEST ============\n",
        "\n",
        "cats  = set()\n",
        "preds = set()\n",
        "\n",
        "for split in (train_ann, test_ann):\n",
        "    for item in split:\n",
        "        for r in iter_relationships_vrd(item):\n",
        "            cats.add(r['subj'])\n",
        "            cats.add(r['obj'])\n",
        "            if r['predicate'] != 'none':\n",
        "                preds.add(r['predicate'])\n",
        "\n",
        "# thêm 'unknown' & sắp xếp\n",
        "cats  = sorted(cats | {'unknown'})\n",
        "preds = sorted(preds)\n",
        "\n",
        "print(\"Số lượng categories:\", len(cats))\n",
        "print(\"Một vài category:\", cats[:20])\n",
        "print(\"Số lượng predicates (không tính 'none'):\", len(preds))\n",
        "print(\"Một vài predicates:\", preds[:20])\n",
        "\n",
        "# vocab toàn cục\n",
        "NODES_VOCAB = cats\n",
        "REL_VOCAB   = preds + ['none']\n",
        "REL_NO_NONE = preds\n",
        "\n",
        "node2id = {n: i for i, n in enumerate(NODES_VOCAB)}\n",
        "rel2id  = {r: i for i, r in enumerate(REL_VOCAB)}\n",
        "rel2id_no_none = {r: i for i, r in enumerate(REL_NO_NONE)}\n",
        "\n",
        "def one_hot(idx, size):\n",
        "    v = np.zeros(size, dtype=np.float32)\n",
        "    v[idx] = 1.0\n",
        "    return v\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f1e58b6",
      "metadata": {
        "id": "5f1e58b6"
      },
      "source": [
        "## 3) Data splits & batching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40fe68ae-c08e-4826-80e8-0a814b646487",
      "metadata": {
        "id": "40fe68ae-c08e-4826-80e8-0a814b646487"
      },
      "outputs": [],
      "source": [
        "def build_graph_from_item(item, max_nodes=32):\n",
        "    \"\"\"\n",
        "    Xây đồ thị cho 1 ảnh:\n",
        "      - node: category (tên lớp) xuất hiện trong các quan hệ\n",
        "      - edge: (subj, obj) nếu có quan hệ giữa 2 lớp\n",
        "      - R[i,j]: id predicate (nếu không, 'none')\n",
        "      - y: nhãn graph demo (1 nếu có 'person' -- 'wearing' --> 'shirt', v.v. bạn có thể chỉnh)\n",
        "    \"\"\"\n",
        "    rels_norm = list(iter_relationships_vrd(item))\n",
        "\n",
        "    # gom list node\n",
        "    nodes_list = []\n",
        "    for r in rels_norm:\n",
        "        nodes_list.append(r['subj'])\n",
        "        nodes_list.append(r['obj'])\n",
        "    nodes = sorted(set(nodes_list))[:max_nodes]\n",
        "    if not nodes:\n",
        "        nodes = ['unknown']\n",
        "\n",
        "    N = len(nodes)\n",
        "    X = np.stack([one_hot(node2id[n], len(NODES_VOCAB)) for n in nodes], axis=0)\n",
        "    A = np.zeros((N, N), dtype=np.float32)\n",
        "    R = np.full((N, N), rel2id['none'], dtype=np.int64)\n",
        "\n",
        "    for r in rels_norm:\n",
        "        s = r['subj']\n",
        "        o = r['obj']\n",
        "        p = r['predicate']\n",
        "        if s in nodes and o in nodes and s != o and p in rel2id:\n",
        "            i = nodes.index(s)\n",
        "            j = nodes.index(o)\n",
        "            A[i, j] = A[j, i] = 1.0\n",
        "            if p in rel2id_no_none:\n",
        "                R[i, j] = R[j, i] = rel2id[p]\n",
        "\n",
        "    # Nhãn graph demo (tuỳ bạn định nghĩa):\n",
        "    # Ví dụ: 1 nếu có 'woman' -- 'wearing' --> 'shirt'\n",
        "    y = 0\n",
        "    for r in rels_norm:\n",
        "        if (r['predicate'] == 'wearing' and\n",
        "            r['subj'] == 'woman' and\n",
        "            r['obj'] == 'shirt'):\n",
        "            y = 1\n",
        "            break\n",
        "\n",
        "    img_name = item.get('filename') or item.get('file_name') or f\"{item.get('photo_id')}.jpg\"\n",
        "    return A, X, R, y, nodes, img_name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f62c3bd1-6349-4138-8658-34deabed6f1d",
      "metadata": {
        "id": "f62c3bd1-6349-4138-8658-34deabed6f1d",
        "outputId": "a220ffaa-6b89-4194-b072-6f927058ccea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 3400 | Val: 600 | Test: 1000\n",
            "Example graph shapes: (10, 10) (10, 6455) (10, 10) | y: 0 | nodes sample: ['boy', 'goats', 'hat', 'pants', 'road'] | img: 5101356337_86fe7ee94d_b.jpg\n"
          ]
        }
      ],
      "source": [
        "def make_dataset(ann_list):\n",
        "    return [build_graph_from_item(item) for item in ann_list]\n",
        "\n",
        "train_data_all = make_dataset(train_ann)\n",
        "test_data      = make_dataset(test_ann)\n",
        "\n",
        "def split_list(L, va_ratio=0.15, seed=SEED):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    idx = np.arange(len(L)); rng.shuffle(idx)\n",
        "    v = int(len(L) * va_ratio)\n",
        "    return [L[i] for i in idx[v:]], [L[i] for i in idx[:v]]\n",
        "\n",
        "train_data, val_data = split_list(train_data_all, va_ratio=0.15, seed=SEED)\n",
        "\n",
        "print(\"Train:\", len(train_data), \"| Val:\", len(val_data), \"| Test:\", len(test_data))\n",
        "A, X, R, y, nodes, img_name = train_data[0]\n",
        "print(\"Example graph shapes:\", A.shape, X.shape, R.shape,\n",
        "      \"| y:\", y,\n",
        "      \"| nodes sample:\", nodes[:5],\n",
        "      \"| img:\", img_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "657182f7",
      "metadata": {
        "id": "657182f7"
      },
      "outputs": [],
      "source": [
        "def to_tensors_padded(batch, device):\n",
        "    B=len(batch); Ns=[b[0].shape[0] for b in batch]; Nmax=max(Ns); F=batch[0][1].shape[1]\n",
        "    A=np.zeros((B,Nmax,Nmax),dtype=np.float32)\n",
        "    X=np.zeros((B,Nmax,F),dtype=np.float32)\n",
        "    R=np.full((B,Nmax,Nmax), rel2id['none'], dtype=np.int64)\n",
        "    M=np.zeros((B,Nmax),dtype=np.float32)\n",
        "    y=np.zeros(B,dtype=np.int64); nodes_list=[]; img_names=[]\n",
        "    for i,(Ai,Xi,Ri,yi,nodes,img_name) in enumerate(batch):\n",
        "        n=Ai.shape[0]\n",
        "        A[i,:n,:n]=Ai; X[i,:n,:]=Xi; R[i,:n,:n]=Ri; M[i,:n]=1.0; y[i]=yi\n",
        "        nodes_list.append(nodes); img_names.append(img_name)\n",
        "    return (torch.tensor(A,dtype=torch.float32,device=device),\n",
        "            torch.tensor(X,dtype=torch.float32,device=device),\n",
        "            torch.tensor(R,dtype=torch.long,device=device),\n",
        "            torch.tensor(M,dtype=torch.float32,device=device),\n",
        "            torch.tensor(y,dtype=torch.long,device=device),\n",
        "            nodes_list, img_names)\n",
        "\n",
        "def batches(data, bs=32):\n",
        "    for i in range(0, len(data), bs):\n",
        "        yield data[i:i+bs]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd1a47bc",
      "metadata": {
        "id": "dd1a47bc"
      },
      "source": [
        "## 4) Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a3e6869",
      "metadata": {
        "id": "7a3e6869"
      },
      "outputs": [],
      "source": [
        "\n",
        "class RelGATLayer(nn.Module):\n",
        "    def __init__(self,in_dim,out_dim,n_rel,heads=2,dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.heads=heads; self.dk=out_dim//heads; assert out_dim%heads==0\n",
        "        self.Wq=nn.Linear(in_dim,out_dim,bias=False)\n",
        "        self.Wk=nn.Linear(in_dim,out_dim,bias=False)\n",
        "        self.Wv=nn.Linear(in_dim,out_dim,bias=False)\n",
        "        self.rel_emb=nn.Embedding(n_rel, self.dk)\n",
        "        self.dp=nn.Dropout(dropout)\n",
        "    def forward(self,X,A,R,mask):\n",
        "        B,N,F=X.shape; H=self.heads; dk=self.dk\n",
        "        X=X*mask.unsqueeze(-1)\n",
        "        Q=self.Wq(X).view(B,N,H,dk); K=self.Wk(X).view(B,N,H,dk); V=self.Wv(X).view(B,N,H,dk)\n",
        "        rel=self.rel_emb(R).view(B,N,N,dk)\n",
        "        logits=torch.einsum('bnhd,bmhd->bhnm',Q,K)/(dk**0.5)\n",
        "        logits=logits+torch.einsum('bnhd,bnmd->bhnm',Q,rel)\n",
        "        edge_mask=(A==0).unsqueeze(1); pad_mask=(mask==0).unsqueeze(1).unsqueeze(2)\n",
        "        logits=logits.masked_fill(edge_mask|pad_mask,-1e9)\n",
        "        attn=torch.softmax(logits,dim=-1); attn=self.dp(attn)\n",
        "        out=torch.einsum('bhnm,bmhd->bnhd',attn,V).contiguous().view(B,N,H*dk)\n",
        "        out=out*mask.unsqueeze(-1); return out,attn\n",
        "\n",
        "class GraphClassifier(nn.Module):\n",
        "    def __init__(self,in_dim,hid_dim,n_rel,heads=2):\n",
        "        super().__init__()\n",
        "        self.g1=RelGATLayer(in_dim,hid_dim,n_rel,heads=heads,dropout=0.1)\n",
        "        self.g2=RelGATLayer(hid_dim,hid_dim,n_rel,heads=heads,dropout=0.1)\n",
        "        self.cls=nn.Sequential(nn.Linear(hid_dim,hid_dim), nn.ReLU(), nn.Linear(hid_dim,2))\n",
        "    def forward(self,X,A,R,mask):\n",
        "        H1,_=self.g1(X,A,R,mask); H1=F.relu(H1)\n",
        "        H2,_=self.g2(H1,A,R,mask); H2=F.relu(H2)\n",
        "        m=mask.unsqueeze(-1); g=(H2*m).sum(dim=1)/m.sum(dim=1).clamp_min(1e-6)\n",
        "        return self.cls(g)\n",
        "\n",
        "class RelationExtractor(nn.Module):\n",
        "    def __init__(self,in_dim,hid_dim,n_rel,heads=2):\n",
        "        super().__init__()\n",
        "        self.g1=RelGATLayer(in_dim,hid_dim,n_rel,heads=heads,dropout=0.1)\n",
        "        self.g2=RelGATLayer(hid_dim,hid_dim,n_rel,heads=heads,dropout=0.1)\n",
        "        self.edge_mlp=nn.Sequential(nn.Linear(2*hid_dim,hid_dim), nn.ReLU(), nn.Linear(hid_dim, len(REL_NO_NONE)))\n",
        "    def forward(self,X,A,R,mask):\n",
        "        H1,_=self.g1(X,A,R,mask); H1=F.relu(H1)\n",
        "        H2,_=self.g2(H1,A,R,mask); H2=F.relu(H2)\n",
        "        return H2\n",
        "    def edge_logits(self,H,pairs):\n",
        "        B,P,_=pairs.shape; i=pairs[...,0]; j=pairs[...,1]\n",
        "        Hi=H.gather(1, i.unsqueeze(-1).expand(-1,-1,H.size(-1)))\n",
        "        Hj=H.gather(1, j.unsqueeze(-1).expand(-1,-1,H.size(-1)))\n",
        "        feat=torch.cat([Hi,Hj],dim=-1)\n",
        "        return self.edge_mlp(feat)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc375504",
      "metadata": {
        "id": "dc375504"
      },
      "source": [
        "## 5) Train loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0308e8d",
      "metadata": {
        "id": "a0308e8d",
        "outputId": "b90a8898-ded2-4d18-f8d1-cf7469afbfbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | loss=0.4725 | val_graph_acc=0.942\n",
            "Epoch 02 | loss=0.2063 | val_graph_acc=0.942\n",
            "Epoch 03 | loss=0.1665 | val_graph_acc=0.942\n",
            "Epoch 04 | loss=0.1342 | val_graph_acc=0.942\n",
            "Epoch 05 | loss=0.0953 | val_graph_acc=0.945\n",
            "Epoch 06 | loss=0.0557 | val_graph_acc=0.960\n",
            "Epoch 07 | loss=0.0295 | val_graph_acc=0.967\n",
            "Epoch 08 | loss=0.0169 | val_graph_acc=0.972\n",
            "Epoch 09 | loss=0.0100 | val_graph_acc=0.967\n",
            "Epoch 10 | loss=0.0080 | val_graph_acc=0.970\n",
            "Graph Task — Best Val: 0.972 | Test: 0.966\n",
            "Epoch 01 | edge_loss=4.9687 | val_edge_acc=0.218\n",
            "Epoch 02 | edge_loss=3.0134 | val_edge_acc=0.218\n",
            "Epoch 03 | edge_loss=2.9626 | val_edge_acc=0.218\n",
            "Epoch 04 | edge_loss=2.9413 | val_edge_acc=0.218\n",
            "Epoch 05 | edge_loss=2.9121 | val_edge_acc=0.222\n",
            "Epoch 06 | edge_loss=2.8242 | val_edge_acc=0.264\n",
            "Epoch 07 | edge_loss=2.7626 | val_edge_acc=0.269\n",
            "Epoch 08 | edge_loss=2.7255 | val_edge_acc=0.272\n",
            "Epoch 09 | edge_loss=2.7019 | val_edge_acc=0.272\n",
            "Epoch 10 | edge_loss=2.6806 | val_edge_acc=0.272\n",
            "Epoch 11 | edge_loss=2.6633 | val_edge_acc=0.270\n",
            "Epoch 12 | edge_loss=2.6422 | val_edge_acc=0.277\n",
            "Epoch 13 | edge_loss=2.6242 | val_edge_acc=0.280\n",
            "Epoch 14 | edge_loss=2.6001 | val_edge_acc=0.285\n",
            "Epoch 15 | edge_loss=2.5730 | val_edge_acc=0.296\n",
            "Edge Task — Best Val: 0.296 | Test: 0.302\n"
          ]
        }
      ],
      "source": [
        "\n",
        "gc_model=GraphClassifier(in_dim=len(NODES_VOCAB), hid_dim=64, n_rel=len(REL_VOCAB), heads=2).to(device)\n",
        "gc_opt=optim.Adam(gc_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "crit=nn.CrossEntropyLoss()\n",
        "\n",
        "def eval_graph_acc(dataset, bs=64):\n",
        "    gc_model.eval(); correct=0; total=0\n",
        "    with torch.no_grad():\n",
        "        for batch in batches(dataset, bs):\n",
        "            A,X,R,M,y,_,_=to_tensors_padded(batch, device)\n",
        "            pred=gc_model(X,A,R,M).argmax(1)\n",
        "            correct += (pred==y).sum().item(); total+=y.numel()\n",
        "    return correct/total if total>0 else 0.0\n",
        "\n",
        "best=(0.0,None)\n",
        "for ep in range(1,11):\n",
        "    gc_model.train(); losses=[]\n",
        "    for batch in batches(train_data,64):\n",
        "        A,X,R,M,y,_,_=to_tensors_padded(batch, device)\n",
        "        logits=gc_model(X,A,R,M); loss=crit(logits,y)\n",
        "        gc_opt.zero_grad(); loss.backward(); gc_opt.step(); losses.append(loss.item())\n",
        "    va=eval_graph_acc(val_data)\n",
        "    if va>best[0]: best=(va, {k:v.detach().cpu().clone() for k,v in gc_model.state_dict().items()})\n",
        "    print(f\"Epoch {ep:02d} | loss={np.mean(losses):.4f} | val_graph_acc={va:.3f}\")\n",
        "if best[1] is not None: gc_model.load_state_dict(best[1])\n",
        "te=eval_graph_acc(test_data); print('Graph Task — Best Val:', round(best[0],3), '| Test:', round(te,3))\n",
        "\n",
        "re_model=RelationExtractor(in_dim=len(NODES_VOCAB), hid_dim=128, n_rel=len(REL_VOCAB), heads=2).to(device)\n",
        "re_opt=optim.Adam(re_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "edge_crit=nn.CrossEntropyLoss()\n",
        "\n",
        "def build_edge_targets(A,R,M):\n",
        "    B,N,_=A.shape; pairs_list=[]; targets_list=[]\n",
        "    for b in range(B):\n",
        "        valid=(M[b]>0.5).nonzero(as_tuple=False).flatten()\n",
        "        if valid.numel()<2: continue\n",
        "        Ai=A[b][valid][:,valid]; Ri=R[b][valid][:,valid]\n",
        "        idxs=(Ai>0.5).nonzero(as_tuple=False)\n",
        "        keep=[]; targ=[]\n",
        "        for ii,jj in idxs.tolist():\n",
        "            rel_id=int(Ri[ii,jj].item()); rn=REL_VOCAB[rel_id]\n",
        "            if rn=='none': continue\n",
        "            keep.append([ii,jj]); targ.append(rel2id_no_none[rn])\n",
        "        if not keep: continue\n",
        "        pairs=valid[torch.tensor(keep, dtype=torch.long, device=A.device)]\n",
        "        pairs_list.append(pairs)\n",
        "        targets_list.append(torch.tensor(targ, dtype=torch.long, device=A.device))\n",
        "    if not pairs_list: return None, None\n",
        "    P=min(p.size(0) for p in pairs_list)\n",
        "    pairs=torch.stack([p[:P] for p in pairs_list], dim=0); targets=torch.stack([t[:P] for t in targets_list], dim=0)\n",
        "    return pairs, targets\n",
        "\n",
        "def evaluate_edge_acc(dataset, bs=48):\n",
        "    re_model.eval(); correct=0; total=0\n",
        "    with torch.no_grad():\n",
        "        for batch in batches(dataset, bs):\n",
        "            A,X,R,M,_,_,_ = to_tensors_padded(batch, device)\n",
        "            H=re_model(X,A,R,M)\n",
        "            pairs,targets=build_edge_targets(A,R,M)\n",
        "            if pairs is None: continue\n",
        "            logits=re_model.edge_logits(H,pairs)\n",
        "            pred=logits.argmax(-1)\n",
        "            correct += (pred==targets).sum().item(); total+=targets.numel()\n",
        "    return correct/total if total>0 else 0.0\n",
        "\n",
        "best=(0.0,None)\n",
        "for ep in range(1,16):\n",
        "    re_model.train(); losses=[]\n",
        "    for batch in batches(train_data,48):\n",
        "        A,X,R,M,_,_,_=to_tensors_padded(batch, device)\n",
        "        H=re_model(X,A,R,M)\n",
        "        pairs,targets=build_edge_targets(A,R,M)\n",
        "        if pairs is None: continue\n",
        "        logits=re_model.edge_logits(H,pairs)\n",
        "        loss=edge_crit(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
        "        re_opt.zero_grad(); loss.backward(); re_opt.step(); losses.append(loss.item())\n",
        "    va=evaluate_edge_acc(val_data, bs=48)\n",
        "    if va>best[0]: best=(va, {k:v.detach().cpu().clone() for k,v in re_model.state_dict().items()})\n",
        "    print(f\"Epoch {ep:02d} | edge_loss={np.mean(losses):.4f} | val_edge_acc={va:.3f}\")\n",
        "if best[1] is not None: re_model.load_state_dict(best[1])\n",
        "te=evaluate_edge_acc(test_data, bs=48)\n",
        "print('Edge Task — Best Val:', round(best[0],3), '| Test:', round(te,3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f8d63e5",
      "metadata": {
        "id": "4f8d63e5"
      },
      "source": [
        "## 6) YOLOv8 detection → inference từ ảnh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7379a274",
      "metadata": {
        "id": "7379a274"
      },
      "outputs": [],
      "source": [
        "\n",
        "from PIL import Image\n",
        "\n",
        "def map_det_name(name: str):\n",
        "    # map tên lớp YOLO về vocab VRD; nếu không có thì 'unknown'\n",
        "    return name if name in node2id else 'unknown'\n",
        "\n",
        "def yolo_detect(image_path: Path, conf=0.25, model_name='yolov8n.pt'):\n",
        "    if not HAS_YOLO:\n",
        "        raise RuntimeError(\"YOLOv8 chưa sẵn sàng. Hãy cài ultralytics hoặc đặt HAS_YOLO=True với model đã load.\")\n",
        "    model = YOLO(model_name)\n",
        "    res = model.predict(source=str(image_path), conf=conf, verbose=False)[0]\n",
        "    dets = []  # [(name, [x1,y1,x2,y2], score)]\n",
        "    for b in res.boxes:\n",
        "        cls_id = int(b.cls.item())\n",
        "        name = res.names.get(cls_id, str(cls_id))\n",
        "        xyxy = b.xyxy[0].tolist()\n",
        "        score = float(b.conf.item())\n",
        "        dets.append((name, xyxy, score))\n",
        "    return dets\n",
        "\n",
        "def build_graph_from_dets(dets, max_nodes=20):\n",
        "    \"\"\"\n",
        "    dets: list (name, bbox, score)\n",
        "    Trả về: A, X, R, nodes, pairs\n",
        "    \"\"\"\n",
        "    names = [map_det_name(n) for (n, _, _) in dets]\n",
        "    # nodes = các lớp (category) xuất hiện\n",
        "    nodes = sorted(set(names))[:max_nodes]\n",
        "    if not nodes:\n",
        "        # không có đối tượng nào\n",
        "        return (\n",
        "            np.zeros((0, 0), dtype=np.float32),\n",
        "            np.zeros((0, len(NODES_VOCAB)), dtype=np.float32),\n",
        "            np.zeros((0, 0), dtype=np.int64),\n",
        "            [],\n",
        "            []\n",
        "        )\n",
        "\n",
        "    N = len(nodes)\n",
        "    X = np.stack([one_hot(node2id[n], len(NODES_VOCAB)) for n in nodes], axis=0)\n",
        "    A = np.zeros((N, N), dtype=np.float32)\n",
        "    R = np.full((N, N), rel2id['none'], dtype=np.int64)\n",
        "\n",
        "    pairs = []\n",
        "    # Ở đây cho full graph; bạn có thể thay bằng nối theo proximity nếu muốn\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            if i != j:\n",
        "                A[i, j] = A[j, i] = 1.0\n",
        "                pairs.append((i, j))\n",
        "\n",
        "    return A, X, R, nodes, pairs\n",
        "\n",
        "def infer_image(image_path: Path,\n",
        "                yolo_model='yolov8n.pt',\n",
        "                conf=0.25,\n",
        "                topk=10,\n",
        "                threshold=0.2):\n",
        "    \"\"\"\n",
        "    Trả về: strings, triples, nodes, dets\n",
        "      - strings: list chuỗi \"<object> <relation> <subject>\"\n",
        "      - triples: list (subj, rel, obj, confidence)\n",
        "      - nodes:   danh sách node (category) trong graph\n",
        "      - dets:    detections gốc từ YOLO hoặc anotations VRD (fallback)\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Lấy detections\n",
        "    if HAS_YOLO:\n",
        "        dets = yolo_detect(image_path, conf=conf, model_name=yolo_model)\n",
        "    else:\n",
        "        dets = []\n",
        "        # fallback: dùng anotations VRD nếu trùng tên file\n",
        "        for split in (train_ann, test_ann):\n",
        "            for item in split:\n",
        "                fn = item.get('file_name') or f\"{item.get('image_id')}.jpg\"\n",
        "                if fn == image_path.name:\n",
        "                    for r in item.get('relationships', item.get('rels', [])):\n",
        "                        dets.append(\n",
        "                            (safe_cat(r.get('subject', {}).get('category', 'unknown')), None, 1.0)\n",
        "                        )\n",
        "                        dets.append(\n",
        "                            (safe_cat(r.get('object', {}).get('category', 'unknown')), None, 1.0)\n",
        "                        )\n",
        "                    break\n",
        "\n",
        "    # Nếu hoàn toàn không có dets → trả về rỗng nhưng đủ 4 phần\n",
        "    if len(dets) == 0:\n",
        "        print(f\"[WARN] Không tìm thấy detection / anotations nào cho ảnh: {image_path}\")\n",
        "        return [], [], [], dets\n",
        "\n",
        "    # 2) Xây graph từ dets\n",
        "    A, X, R, nodes, pairs = build_graph_from_dets(dets)\n",
        "    n = A.shape[0]\n",
        "\n",
        "    if n == 0 or len(pairs) == 0:\n",
        "        print(f\"[WARN] Graph sau khi build không có node/cạnh hợp lệ cho ảnh: {image_path}\")\n",
        "        return [], [], nodes, dets\n",
        "\n",
        "    A_t = torch.tensor(A, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "    X_t = torch.tensor(X, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "    R_t = torch.tensor(R, dtype=torch.long,    device=device).unsqueeze(0)\n",
        "    M_t = torch.ones(1, n, dtype=torch.float32, device=device)\n",
        "\n",
        "    # 3) Chạy RelationExtractor\n",
        "    re_model.eval()\n",
        "    with torch.no_grad():\n",
        "        H = re_model(X_t, A_t, R_t, M_t)\n",
        "        pairs_t = torch.tensor(pairs, dtype=torch.long, device=device).unsqueeze(0)\n",
        "        logits = re_model.edge_logits(H, pairs_t).squeeze(0)  # [P, |REL_NO_NONE|]\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "        confs, preds = probs.max(dim=-1)\n",
        "\n",
        "    # 4) Lọc theo threshold + sort\n",
        "    triples = []\n",
        "    for (i, j), c, p in zip(\n",
        "        pairs,\n",
        "        confs.cpu().numpy().tolist(),\n",
        "        preds.cpu().numpy().tolist()\n",
        "    ):\n",
        "        rel = REL_NO_NONE[p]\n",
        "        s = nodes[i]\n",
        "        o = nodes[j]\n",
        "        if (threshold is not None) and (c < threshold):\n",
        "            continue\n",
        "        triples.append((s, rel, o, float(c)))\n",
        "\n",
        "    triples.sort(key=lambda x: -x[3])\n",
        "    if topk is not None:\n",
        "        triples = triples[:topk]\n",
        "\n",
        "    strings = [f\"{subj} {rel} {obj}\" for (subj, rel, obj, _) in triples]\n",
        "    return strings, triples, nodes, dets\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45aad316",
      "metadata": {
        "id": "45aad316"
      },
      "source": [
        "### 7) Demo: suy luận trên 1 ảnh test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ee61e48",
      "metadata": {
        "id": "1ee61e48",
        "outputId": "085b0001-025a-4442-a9e0-69025f84eee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image: H:\\Download\\vrd\\sg_test_images\\116298453_57a957315a_o.jpg\n",
            "Nodes: ['book', 'keyboard', 'mouse', 'tv']\n",
            "Predicted triples:\n",
            "  mouse on keyboard  (conf=0.199)\n",
            "  tv on keyboard  (conf=0.195)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Chọn ảnh từ thư mục test và chạy\n",
        "#############################################################################\n",
        "sample = test_ann[0]\n",
        "img_name = '116298453_57a957315a_o.jpg'\n",
        "img_path = (Path(VRD_TEST_DIR) / img_name)\n",
        "print('Image:', img_path)\n",
        "\n",
        "strings, triples, nodes, dets = infer_image(\n",
        "    img_path,\n",
        "    yolo_model='yolov8n.pt',\n",
        "    conf=0.25,\n",
        "    topk=15,\n",
        "    threshold=0.195\n",
        ")\n",
        "print('Nodes:', nodes)\n",
        "print('Predicted triples:')\n",
        "for subj, rel, obj, c in triples:\n",
        "    print(f\"  {subj} {rel} {obj}  (conf={c:.3f})\")\n",
        "#for s in strings:\n",
        "#    print('  ', s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e82cf758-fa3f-4a9b-a2d7-ae92461b7f86",
      "metadata": {
        "id": "e82cf758-fa3f-4a9b-a2d7-ae92461b7f86"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9790d9d6"
      },
      "source": [
        "# Task\n",
        "Implement a proximity-based graph construction method for scene graph generation within the existing GCN+YOLO framework, enhance the YOLO-VRD class name mapping, and then compare its inference performance against the full graph method on selected VRD test images. Perform a qualitative analysis by visually comparing predicted scene graphs with ground truth annotations and summarize the findings, including the effectiveness of both graph construction approaches and the overall GCN+YOLO model performance."
      ],
      "id": "9790d9d6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5b4e5f9"
      },
      "source": [
        "## Implement Proximity Graph\n",
        "\n",
        "### Subtask:\n",
        "Implement a new function `build_graph_from_dets_proximity` to construct an adjacency matrix `A` based on the proximity of detected bounding boxes, instead of creating a full graph.\n"
      ],
      "id": "f5b4e5f9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31285b42"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to implement the `build_graph_from_dets_proximity` function as described in the instructions, which involves extracting bounding box information, calculating distances, and constructing the adjacency matrix based on proximity. This code block will contain the complete implementation of the function.\n",
        "\n"
      ],
      "id": "31285b42"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b31cf45"
      },
      "source": [
        "def get_bbox_center(bbox):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    return (x1 + x2) / 2, (y1 + y2) / 2\n",
        "\n",
        "def euclidean_distance(pt1, pt2):\n",
        "    return math.sqrt((pt1[0] - pt2[0])**2 + (pt1[1] - pt2[1])**2)\n",
        "\n",
        "def build_graph_from_dets_proximity(dets, max_nodes=20, threshold_dist=50):\n",
        "    \"\"\"\n",
        "    dets: list (name, bbox, score)\n",
        "    Trả về: A, X, R, nodes, pairs\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Extract object names, bboxes, and map to VRD vocab\n",
        "    # Store (mapped_name, bbox) for each detection\n",
        "    det_info = []\n",
        "    for name, bbox, _ in dets:\n",
        "        mapped_name = map_det_name(name)\n",
        "        det_info.append((mapped_name, bbox))\n",
        "\n",
        "    # 2) Create a list of unique nodes (categories) present in the detections\n",
        "    all_category_names = [info[0] for info in det_info if info[0] != 'unknown']\n",
        "    # Only consider `unknown` if there are no other categories\n",
        "    if not all_category_names and det_info:\n",
        "        all_category_names = ['unknown']\n",
        "\n",
        "    nodes = sorted(list(set(all_category_names)))[:max_nodes]\n",
        "\n",
        "    # 3) If no nodes are found, return empty arrays\n",
        "    if not nodes:\n",
        "        return (\n",
        "            np.zeros((0, 0), dtype=np.float32),\n",
        "            np.zeros((0, len(NODES_VOCAB)), dtype=np.float32),\n",
        "            np.zeros((0, 0), dtype=np.int64),\n",
        "            [],\n",
        "            []\n",
        "        )\n",
        "\n",
        "    N = len(nodes)\n",
        "\n",
        "    # 4) Generate node feature matrix X\n",
        "    X = np.stack([one_hot(node2id[n], len(NODES_VOCAB)) for n in nodes], axis=0)\n",
        "\n",
        "    # 5) Initialize adjacency matrix A and relation matrix R\n",
        "    A = np.zeros((N, N), dtype=np.float32)\n",
        "    R = np.full((N, N), rel2id['none'], dtype=np.int64)\n",
        "    pairs = []\n",
        "\n",
        "    # 6) Iterate through all unique pairs of nodes\n",
        "    for i in range(N):\n",
        "        for j in range(i + 1, N):\n",
        "            node_i_name = nodes[i]\n",
        "            node_j_name = nodes[j]\n",
        "\n",
        "            # Find all detections associated with nodes[i] and nodes[j]\n",
        "            dets_node_i_bboxes = [info[1] for info in det_info if info[0] == node_i_name]\n",
        "            dets_node_j_bboxes = [info[1] for info in det_info if info[0] == node_j_name]\n",
        "\n",
        "            if not dets_node_i_bboxes or not dets_node_j_bboxes:\n",
        "                continue # No detections for one or both nodes, skip proximity check\n",
        "\n",
        "            min_dist = float('inf')\n",
        "            for bbox_i in dets_node_i_bboxes:\n",
        "                center_i = get_bbox_center(bbox_i)\n",
        "                for bbox_j in dets_node_j_bboxes:\n",
        "                    center_j = get_bbox_center(bbox_j)\n",
        "                    dist = euclidean_distance(center_i, center_j)\n",
        "                    min_dist = min(min_dist, dist)\n",
        "\n",
        "            # 7) If minimum distance is less than threshold_dist, set A[i,j] and add to pairs\n",
        "            if min_dist < threshold_dist:\n",
        "                A[i, j] = 1.0\n",
        "                A[j, i] = 1.0 # Adjacency is symmetric\n",
        "                pairs.append((i, j))\n",
        "                # R is not filled here as this is just for building the graph structure\n",
        "\n",
        "    return A, X, R, nodes, pairs\n",
        "\n",
        "print(\"Defined build_graph_from_dets_proximity function.\")"
      ],
      "id": "4b31cf45",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11fb2b40"
      },
      "source": [
        "## Integrate Proximity Graph into Inference\n",
        "\n",
        "### Subtask:\n",
        "Cập nhật hàm `infer_image` để có thể sử dụng ma trận kề A được xây dựng từ `build_graph_from_dets_proximity`. Điều này sẽ cho phép so sánh kết quả suy luận giữa hai phương pháp xây dựng đồ thị.\n"
      ],
      "id": "11fb2b40"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "744ac6b1"
      },
      "source": [
        "from PIL import Image\n",
        "from pathlib import Path # Added this import\n",
        "\n",
        "def map_det_name(name: str):\n",
        "    # map tên lớp YOLO về vocab VRD; nếu không có thì 'unknown'\n",
        "    return name if name in node2id else 'unknown'\n",
        "\n",
        "def yolo_detect(image_path: Path, conf=0.25, model_name='yolov8n.pt'):\n",
        "    if not HAS_YOLO:\n",
        "        raise RuntimeError(\"YOLOv8 chưa sẵn sàng. Hãy cài ultralytics hoặc đặt HAS_YOLO=True với model đã load.\")\n",
        "    model = YOLO(model_name)\n",
        "    res = model.predict(source=str(image_path), conf=conf, verbose=False)[0]\n",
        "    dets = []  # [(name, [x1,y1,x2,y2], score)]\n",
        "    for b in res.boxes:\n",
        "        cls_id = int(b.cls.item())\n",
        "        name = res.names.get(cls_id, str(cls_id))\n",
        "        xyxy = b.xyxy[0].tolist()\n",
        "        score = float(b.conf.item())\n",
        "        dets.append((name, xyxy, score))\n",
        "    return dets\n",
        "\n",
        "def build_graph_from_dets(dets, max_nodes=20):\n",
        "    \"\"\"\n",
        "    dets: list (name, bbox, score)\n",
        "    Trả về: A, X, R, nodes, pairs\n",
        "    \"\"\"\n",
        "    names = [map_det_name(n) for (n, _, _) in dets]\n",
        "    # nodes = các lớp (category) xuất hiện\n",
        "    nodes = sorted(set(names))[:max_nodes]\n",
        "    if not nodes:\n",
        "        # không có đối tượng nào\n",
        "        return (\n",
        "            np.zeros((0, 0), dtype=np.float32),\n",
        "            np.zeros((0, len(NODES_VOCAB)), dtype=np.float32),\n",
        "            np.zeros((0, 0), dtype=np.int64),\n",
        "            [],\n",
        "            []\n",
        "        )\n",
        "\n",
        "    N = len(nodes)\n",
        "    X = np.stack([one_hot(node2id[n], len(NODES_VOCAB)) for n in nodes], axis=0)\n",
        "    A = np.zeros((N, N), dtype=np.float32)\n",
        "    R = np.full((N, N), rel2id['none'], dtype=np.int64)\n",
        "\n",
        "    pairs = []\n",
        "    # Ở đây cho full graph; bạn có thể thay bằng nối theo proximity nếu muốn\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            if i != j:\n",
        "                A[i, j] = A[j, i] = 1.0\n",
        "                pairs.append((i, j))\n",
        "\n",
        "    return A, X, R, nodes, pairs\n",
        "\n",
        "def infer_image(image_path: Path,\n",
        "                yolo_model='yolov8n.pt',\n",
        "                conf=0.25,\n",
        "                topk=10,\n",
        "                threshold=0.2,\n",
        "                graph_construction_method='full', # New parameter\n",
        "                proximity_threshold=50):            # New parameter\n",
        "    \"\"\"\n",
        "    Trả về: strings, triples, nodes, dets\n",
        "      - strings: list chuỗi \"<object> <relation> <subject>\"\n",
        "      - triples: list (subj, rel, obj, confidence)\n",
        "      - nodes:   danh sách node (category) trong graph\n",
        "      - dets:    detections gốc từ YOLO hoặc anotations VRD (fallback)\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Lấy detections\n",
        "    if HAS_YOLO:\n",
        "        dets = yolo_detect(image_path, conf=conf, model_name=yolo_model)\n",
        "    else:\n",
        "        dets = []\n",
        "        # fallback: dùng anotations VRD nếu trùng tên file\n",
        "        for split in (train_ann, test_ann):\n",
        "            for item in split:\n",
        "                fn = item.get('file_name') or f\"{item.get('image_id')}.jpg\"\n",
        "                if fn == image_path.name:\n",
        "                    for r in item.get('relationships', item.get('rels', [])):\n",
        "                        dets.append(\n",
        "                            (safe_cat(r.get('subject', {}).get('category', 'unknown')), None, 1.0)\n",
        "                        )\n",
        "                        dets.append(\n",
        "                            (safe_cat(r.get('object', {}).get('category', 'unknown')), None, 1.0)\n",
        "                        )\n",
        "                    break\n",
        "\n",
        "    # Nếu hoàn toàn không có dets → trả về rỗng nhưng đủ 4 phần\n",
        "    if len(dets) == 0:\n",
        "        print(f\"[WARN] Không tìm thấy detection / anotations nào cho ảnh: {image_path}\")\n",
        "        return [], [], [], dets\n",
        "\n",
        "    # 2) Xây graph từ dets, chọn phương pháp xây dựng đồ thị\n",
        "    if graph_construction_method == 'proximity':\n",
        "        A, X, R, nodes, pairs = build_graph_from_dets_proximity(dets, threshold_dist=proximity_threshold)\n",
        "    else:\n",
        "        A, X, R, nodes, pairs = build_graph_from_dets(dets)\n",
        "\n",
        "    n = A.shape[0]\n",
        "\n",
        "    if n == 0 or len(pairs) == 0:\n",
        "        print(f\"[WARN] Graph sau khi build không có node/cạnh hợp lệ cho ảnh: {image_path}\")\n",
        "        return [], [], nodes, dets\n",
        "\n",
        "    A_t = torch.tensor(A, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "    X_t = torch.tensor(X, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "    R_t = torch.tensor(R, dtype=torch.long,    device=device).unsqueeze(0)\n",
        "    M_t = torch.ones(1, n, dtype=torch.float32, device=device)\n",
        "\n",
        "    # 3) Chạy RelationExtractor\n",
        "    re_model.eval()\n",
        "    with torch.no_grad():\n",
        "        H = re_model(X_t, A_t, R_t, M_t)\n",
        "        pairs_t = torch.tensor(pairs, dtype=torch.long, device=device).unsqueeze(0)\n",
        "        logits = re_model.edge_logits(H, pairs_t).squeeze(0)  # [P, |REL_NO_NONE|]\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "        confs, preds = probs.max(dim=-1)\n",
        "\n",
        "    # 4) Lọc theo threshold + sort\n",
        "    triples = []\n",
        "    for (i, j), c, p in zip(\n",
        "        pairs,\n",
        "        confs.cpu().numpy().tolist(),\n",
        "        preds.cpu().numpy().tolist()\n",
        "    ):\n",
        "        rel = REL_NO_NONE[p]\n",
        "        s = nodes[i]\n",
        "        o = nodes[j]\n",
        "        if (threshold is not None) and (c < threshold):\n",
        "            continue\n",
        "        triples.append((s, rel, o, float(c)))\n",
        "\n",
        "    triples.sort(key=lambda x: -x[3])\n",
        "    if topk is not None:\n",
        "        triples = triples[:topk]\n",
        "\n",
        "    strings = [f\"{subj} {rel} {obj}\" for (subj, rel, obj, _) in triples]\n",
        "    return strings, triples, nodes, dets"
      ],
      "id": "744ac6b1",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "425eeddb"
      },
      "source": [
        "## Enhance YOLO-VRD Mapping\n",
        "\n",
        "### Subtask:\n",
        "Mở rộng hàm `map_det_name` để ánh xạ các tên lớp từ YOLO (ví dụ: 'tv', 'bike') sang các lớp gần nghĩa trong VRD (ví dụ: 'television', 'bicycle').\n"
      ],
      "id": "425eeddb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb02046b",
        "outputId": "b6f5f1e4-0ebe-41dd-c906-5a178f574eca"
      },
      "source": [
        "YOLO_TO_VRD_MAPPING = {\n",
        "    'tv': 'television',\n",
        "    'bike': 'bicycle',\n",
        "    'person': 'man', # Mapping 'person' to 'man' as a common equivalent in VRD, can be adjusted\n",
        "    'car': 'automobile',\n",
        "    'bus': 'bus',\n",
        "    'truck': 'truck',\n",
        "    'motorcycle': 'motorcycle',\n",
        "    'airplane': 'plane',\n",
        "    'boat': 'boat',\n",
        "    'traffic light': 'traffic light',\n",
        "    'fire hydrant': 'fire hydrant',\n",
        "    'stop sign': 'stop sign',\n",
        "    'parking meter': 'parking meter',\n",
        "    'bench': 'bench',\n",
        "    'bird': 'bird',\n",
        "    'cat': 'cat',\n",
        "    'dog': 'dog',\n",
        "    'horse': 'horse',\n",
        "    'sheep': 'sheep',\n",
        "    'cow': 'cow',\n",
        "    'elephant': 'elephant',\n",
        "    'bear': 'bear',\n",
        "    'zebra': 'zebra',\n",
        "    'giraffe': 'giraffe',\n",
        "    'backpack': 'backpack',\n",
        "    'umbrella': 'umbrella',\n",
        "    'handbag': 'handbag',\n",
        "    'tie': 'tie',\n",
        "    'suitcase': 'suitcase',\n",
        "    'frisbee': 'frisbee',\n",
        "    'skis': 'skis',\n",
        "    'snowboard': 'snowboard',\n",
        "    'sports ball': 'ball',\n",
        "    'kite': 'kite',\n",
        "    'baseball bat': 'baseball bat',\n",
        "    'baseball glove': 'baseball glove',\n",
        "    'skateboard': 'skateboard',\n",
        "    'surfboard': 'surfboard',\n",
        "    'tennis racket': 'tennis racket',\n",
        "    'bottle': 'bottle',\n",
        "    'wine glass': 'wine glass',\n",
        "    'cup': 'cup',\n",
        "    'fork': 'fork',\n",
        "    'knife': 'knife',\n",
        "    'spoon': 'spoon',\n",
        "    'bowl': 'bowl',\n",
        "    'banana': 'banana',\n",
        "    'apple': 'apple',\n",
        "    'sandwich': 'sandwich',\n",
        "    'orange': 'orange',\n",
        "    'broccoli': 'broccoli',\n",
        "    'carrot': 'carrot',\n",
        "    'hot dog': 'hot dog',\n",
        "    'pizza': 'pizza',\n",
        "    'donut': 'donut',\n",
        "    'cake': 'cake',\n",
        "    'chair': 'chair',\n",
        "    'couch': 'couch',\n",
        "    'potted plant': 'plant',\n",
        "    'bed': 'bed',\n",
        "    'dining table': 'table',\n",
        "    'toilet': 'toilet',\n",
        "    'laptop': 'laptop',\n",
        "    'mouse': 'mouse',\n",
        "    'remote': 'remote',\n",
        "    'keyboard': 'keyboard',\n",
        "    'cell phone': 'cell phone',\n",
        "    'microwave': 'microwave',\n",
        "    'oven': 'oven',\n",
        "    'toaster': 'toaster',\n",
        "    'sink': 'sink',\n",
        "    'refrigerator': 'refrigerator',\n",
        "    'book': 'book',\n",
        "    'clock': 'clock',\n",
        "    'vase': 'vase',\n",
        "    'scissors': 'scissors',\n",
        "    'teddy bear': 'teddy bear',\n",
        "    'hair drier': 'hair drier',\n",
        "    'toothbrush': 'toothbrush'\n",
        "}\n",
        "\n",
        "def map_det_name(name: str):\n",
        "    # 1. Check if the name exists in YOLO_TO_VRD_MAPPING\n",
        "    mapped_name = YOLO_TO_VRD_MAPPING.get(name, name)\n",
        "\n",
        "    # 2. Then, check if this (either original or mapped) name exists in node2id\n",
        "    if mapped_name in node2id:\n",
        "        return mapped_name\n",
        "\n",
        "    # 3. If the name is not found in the mapping or node2id, return 'unknown'\n",
        "    return 'unknown'\n",
        "\n",
        "print('YOLO_TO_VRD_MAPPING and updated map_det_name function defined.')"
      ],
      "id": "cb02046b",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLO_TO_VRD_MAPPING and updated map_det_name function defined.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}